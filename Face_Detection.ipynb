{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317af5de-e9ac-4904-aa76-5f1588b26ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose 0 for Sharpen\n",
      "Choose 1 for Blur\n",
      "Choose 2 for Outline\n",
      "Choose 3 for Emboss\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please choose:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected kernel ([):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the cascade classifier\n",
    "cascade_path = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + cascade_path)\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError(f\"Cannot load cascade classifier xml file at {cv2.data.haarcascades + cascade_path}\")\n",
    "\n",
    "# Define the face detection function\n",
    "def detect_face(img):\n",
    "    face_img = img.copy()\n",
    "    face_rects = face_cascade.detectMultiScale(face_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return face_img, face_rects\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    raise IOError(\"Cannot read from webcam! Please restart.\")\n",
    "\n",
    "frame, face_rects = detect_face(frame)\n",
    "if len(face_rects) == 0:\n",
    "    raise IOError(\"No face detected\")\n",
    "\n",
    "(face_x, face_y, w, h) = tuple(face_rects[0])\n",
    "track_window = (face_x, face_y, w, h)\n",
    "\n",
    "roi = frame[face_y:face_y + h, face_x:face_x + w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "# Filter parameters\n",
    "arr_sharpen = [0, -1, 0, -1, 5, -1, 0, -1, 0]\n",
    "sharpen = np.array(arr_sharpen).reshape(3, 3).astype(np.float32)\n",
    "\n",
    "arr_blur = [0.0625, 0.125, 0.0625, 0.125, 0.25, 0.125, 0.0625, 0.125, 0.0625]\n",
    "blur = np.array(arr_blur).reshape(3, 3).astype(np.float32)\n",
    "\n",
    "arr_outline = [-1, -1, -1, -1, 8, -1, -1, -1, -1]\n",
    "outline = np.array(arr_outline).reshape(3, 3).astype(np.float32)\n",
    "\n",
    "arr_emboss = [-2, -1, 0, -1, 1, 1, 0, 1, 2]\n",
    "emboss = np.array(arr_emboss).reshape(3, 3).astype(np.float32)\n",
    "\n",
    "arr_identity = [0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "identity = np.array(arr_identity).reshape(3, 3).astype(np.float32)\n",
    "\n",
    "def choose_kernel(choice):\n",
    "    if choice == '0':\n",
    "        return sharpen\n",
    "    elif choice == '1':\n",
    "        return blur\n",
    "    elif choice == '2':\n",
    "        return outline\n",
    "    elif choice == '3':\n",
    "        return emboss\n",
    "    else:\n",
    "        print(\"Invalid choice. Using identity kernel.\")\n",
    "        return identity\n",
    "\n",
    "def bo_loc():\n",
    "    print(\"Choose 0 for Sharpen\")\n",
    "    print(\"Choose 1 for Blur\")\n",
    "    print(\"Choose 2 for Outline\")\n",
    "    print(\"Choose 3 for Emboss\")\n",
    "    choice = input(\"Please choose: \")\n",
    "    return choose_kernel(choice)\n",
    "\n",
    "kernel = bo_loc()\n",
    "kernel_name = str(kernel).split()[0][1:]\n",
    "print(f\"Selected kernel ({kernel_name}):\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame, face_rects = detect_face(frame)\n",
    "    if len(face_rects) > 0:\n",
    "        (x, y, w, h) = tuple(face_rects[0])\n",
    "        track_window = (x, y, w, h)\n",
    "\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        x, y, w, h = track_window\n",
    "\n",
    "        fix_channel_r = np.convolve(frame[:,:,0].flatten(), kernel.flatten(), mode='same').reshape(frame[:,:,0].shape)\n",
    "        fix_channel_g = np.convolve(frame[:,:,1].flatten(), kernel.flatten(), mode='same').reshape(frame[:,:,1].shape)\n",
    "        fix_channel_b = np.convolve(frame[:,:,2].flatten(), kernel.flatten(), mode='same').reshape(frame[:,:,2].shape)\n",
    "        fix = np.stack((fix_channel_r, fix_channel_g, fix_channel_b), axis=2).astype(np.uint8)\n",
    "\n",
    "        mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "        mask[y:y+h, x:x+w] = 255\n",
    "\n",
    "        frame_outside_face = cv2.bitwise_and(fix, fix, mask=cv2.bitwise_not(mask))\n",
    "        frame_inside_face = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "        final_frame = cv2.add(frame_outside_face, frame_inside_face)\n",
    "\n",
    "        img2 = cv2.rectangle(final_frame, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "        cv2.imshow('img', img2)\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c544a6-7471-4d05-b3df-02efd94adacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
